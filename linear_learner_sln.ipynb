{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker workshop: detecting fraudulent credit card transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear models are supervised learning algorithms used for solving either classification or regression problems. For input, you give the model labeled examples (x, y). x is a high-dimensional vector and y is a numeric label. For binary classification problems, the label must be either 0 or 1. For multiclass classification problems, the labels must be from 0 to num_classes - 1. For regression problems, y is a real number. The algorithm learns a linear function, or, for classification problems, a linear threshold function, and maps a vector x to an approximation of the label y.\n",
    "\n",
    "The Amazon SageMaker linear learner algorithm provides a solution for both classification and regression problems. With the Amazon SageMaker algorithm, you can simultaneously explore different training objectives and choose the best solution from a validation set. You can also explore a large number of models and choose the best. The best model optimizes either of the following:\n",
    "\n",
    "- Continuous objectives, such as mean square error, cross entropy loss, absolute error.\n",
    "\n",
    "- Discrete objectives suited for classification, such as F1 measure, precision, recall, or accuracy.\n",
    "\n",
    "Compared with methods that provide a solution for only continuous objectives, the Amazon SageMaker linear learner algorithm provides a significant increase in speed over naive hyperparameter optimization techniques. It is also more convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting credit card fraud\n",
    "\n",
    "In this workshop, we'll look at a credit card fraud detection dataset.  The data set (Dal Pozzolo et al. 2015) was downloaded from [Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud/data).  We have features and labels for over a quarter million credit card transactions, each of which is labeled as fraudulent or not fraudulent.  We'd like to train a model based on the features of these transactions so that we can predict risky or fraudulent transactions in the future.  This is a binary classification problem.  \n",
    "\n",
    "We'll walk through training linear learner with various settings and deploying an inference endpoint.  We'll evaluate the quality of our models by hitting that endpoint with observations from the test set.  We can take the real-time predictions returned by the endpoint and evaluate them against the ground-truth labels in our test set.\n",
    "\n",
    "Next, we'll apply the linear learner threshold tuning functionality to get better precision without sacrificing recall.  Then, we'll push the precision even higher using the linear learner new class weights feature.  Because fraud can be extremely costly, we would prefer to have high recall, even if this means more false positives.  This is especially true if we are building a first line of defense, flagging potentially fraudulent transactions for further review before taking actions that affect customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll do some preprocessing on this data set: we'll shuffle the examples and split them into train and test sets.  To run this under notebook under your own AWS account, you'll need to change the Amazon S3 locations.  First download the raw data from the s3 location below to this instance.  Only 0.17% of the data have positive labels, making this a challenging classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://loftstockholm.s3.eu-central-1.amazonaws.com/creditcard.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we'll have to create an S3 bucket where SageMaker will be reading and writing files to and from (training data, model artifacts, checkpoints,...). Go to the s3 service in the AWS console, create a bucket and fill it in below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Set data locations\n",
    "bucket = 'llworkshop' # TODO: replace this with your own bucket\n",
    "prefix = 'sagemaker/DEMO-linear-learner-loss-weights'\n",
    "s3_train_key = '{}/train/recordio-pb-data'.format(prefix)\n",
    "s3_train_path = os.path.join('s3://', bucket, s3_train_key)\n",
    "local_raw_data = 'creditcard.csv.zip'\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check access to s3 bucket. Attempt reading items in bucket: this shouldn't raise any errors. \n",
    "# You shouldn't get any items if you just created the bucket.\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data, shuffle, and split into train and test sets, separating the labels (last column) from the features\n",
    "raw_data = pd.read_csv(local_raw_data).to_numpy()\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(raw_data)\n",
    "train_size = int(raw_data.shape[0] * 0.7)\n",
    "train_features  = raw_data[:train_size, :-1]\n",
    "train_labels = raw_data[:train_size, -1]\n",
    "test_features = raw_data[train_size:, :-1]\n",
    "test_labels = raw_data[train_size:, -1]\n",
    "\n",
    "# Convert the processed training data to protobuf and write to S3 for linear learner\n",
    "vectors = np.array([t.tolist() for t in train_features]).astype('float32')\n",
    "labels = np.array([t.tolist() for t in train_labels]).astype('float32')\n",
    "buf = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buf, vectors, labels)\n",
    "buf.seek(0)\n",
    "boto3.resource('s3').Bucket(bucket).Object(s3_train_key).upload_fileobj(buf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a convenience function for evaluating the model.  To make predictions, we need to set up a model hosting endpoint.  Then we feed test features to the endpoint and receive predicted test labels.  To evaluate the models we create in this exercise, we'll capture predicted test labels and compare them to actuals using some common binary classification metrics.\n",
    "\n",
    "Complete the code below to calculate recall and precision.\n",
    "See https://en.wikipedia.org/wiki/F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(linear_predictor, test_features, test_labels, model_name, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  Return binary classification metrics.\n",
    "    \"\"\"\n",
    "    # split the test data set into 100 batches and evaluate using prediction endpoint\n",
    "    prediction_batches = [linear_predictor.predict(batch)['predictions'] for batch in np.array_split(test_features, 100)]\n",
    "    # parse raw predictions json to exctract predicted label\n",
    "    test_preds = np.concatenate([np.array([x['predicted_label'] for x in batch]) for batch in prediction_batches])\n",
    "    \n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn) # TODO\n",
    "    precision = tp / (tp + fp) # TODO\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actuals'], colnames=['predictions']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print(\"{:<11} {:.3f}\".format('F1:', f1))\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, 'Precision': precision, 'Recall': recall, 'Accuracy': accuracy, \n",
    "             'F1': f1, 'Model': model_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we'll add a convenience function to delete prediction endpoints after we're done with them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName=predictor.endpoint)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sagemaker provides containers for the built-in algorithms in each region.  \n",
    "You can find the image locations here: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html .  \n",
    "Luckily there's a helper function that does that for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = get_image_uri(boto3.Session().region_name, 'linear-learner')\n",
    "print('Container image for this region: {}'.format(container))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by training a binary classifier model with the linear learner default settings.  Note that we're setting the number of epochs to 40, which is much higher than the default of 15 epochs.  With early stopping, we don't have to worry about setting the number of epochs too high.  Linear learner will stop training automatically after the model has converged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at https://docs.aws.amazon.com/sagemaker/latest/dg/ll_hyperparameters.html to figure out what keys to use in the hyperparams dictionary.\n",
    "\n",
    "The documentation for the Estimator object is here https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.Estimator\n",
    "\n",
    "Tip: see get_execution_role() helper function above which returns this instance's role; you'll need it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a binary classifier with default settings: logistic regression\n",
    "# TODO: construct the hyperparam dict\n",
    "# - 40 epochs\n",
    "# - set the correct predictor type\n",
    "\n",
    "# TODO: construct the estimator\n",
    "# train on 1 ml.c5.4xlarge instance\n",
    "\n",
    "defaults_est = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c5.4xlarge',\n",
    "    output_path='s3://{}/{}/defaults/output'.format(bucket, prefix),\n",
    "    hyperparameters={\n",
    "        'predictor_type': 'binary_classifier',\n",
    "        'epochs': 40\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model. This will take a few minutes.  \n",
    "See: https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: provide path to the training data\n",
    "defaults_est.fit({'train': s3_train_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many epochs did we train for? Why not 40?\n",
    "\n",
    "Deploy an endpoint. This will again take several minutes.  \n",
    "See https://sagemaker.readthedocs.io/en/stable/overview.html#using-estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: deploy an estimator on 1 ml.m4.xlarge instance\n",
    "defaults_predictor = defaults_est.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.m4.xlarge'\n",
    ")\n",
    "defaults_predictor.content_type = 'text/csv'\n",
    "defaults_predictor.serializer = csv_serializer\n",
    "defaults_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our evaluate() helper function to evaluate the defaults_predictor we just deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(defaults_predictor, test_features, test_labels, 'Default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll produce a model with a threshold tuned for the best possible precision with recall fixed at 90%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a binary classifier with automated threshold tuning\n",
    "# TODO: construct the hyper params dict\n",
    "# binary classifier\n",
    "# set precision at target recall as the model selection criteria\n",
    "# set target recall to 0.9\n",
    "# set epochs to 40\n",
    "\n",
    "autothresh_est = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c5.4xlarge',\n",
    "    output_path='s3://{}/{}/autothresh/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    hyperparameters={\n",
    "        'predictor_type': 'binary_classifier',\n",
    "        'binary_classifier_model_selection_criteria': 'precision_at_target_recall', \n",
    "        'target_recall': 0.9,\n",
    "        'epochs': 40\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and deploy an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autothresh_est.fit({'train': s3_train_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: deploy an estimator on 1 ml.m4.xlarge instance\n",
    "autothresh_predictor = autothresh_est.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.m4.xlarge'\n",
    ")\n",
    "autothresh_predictor.content_type = 'text/csv'\n",
    "autothresh_predictor.serializer = csv_serializer\n",
    "autothresh_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluate the deployed endpoint\n",
    "evaluate(autothresh_predictor, test_features, test_labels, 'AutoTresh', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managed spot training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EC2 Spot Instances have long been a great cost optimization feature, and spot training is now available on SageMaker.\n",
    "\n",
    "This blog post has more info: [ https://aws.amazon.com/blogs/aws/managed-spot-training-save-up-to-90-on-your-amazon-sagemaker-training-jobs/ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_est = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m4.xlarge',\n",
    "    output_path='s3://{}/{}/autothresh/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    hyperparameters={\n",
    "        'feature_dim': 30,\n",
    "        'predictor_type': 'binary_classifier',\n",
    "        'binary_classifier_model_selection_criteria': 'precision_at_target_recall', \n",
    "        'target_recall': 0.9,\n",
    "        'epochs': 40\n",
    "    },\n",
    "    train_use_spot_instances=True,\n",
    "    train_max_run=600,\n",
    "    train_max_wait=3600\n",
    ")\n",
    "spot_est.fit({'train': s3_train_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of the cost savings shown at the bottom of the output from the fit() call above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Improving recall with class weights\n",
    "\n",
    "Now we'll improve on these results using a new feature added to linear learner: class weights for binary classification.  We introduced this feature in the *Class Weights* section, and now we'll look into its application to the credit card fraud dataset by training a new model with balanced class weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a binary classifier with class weights and automated threshold tuning\n",
    "# TODO: configure the hyperparams so that Linear Learner will use balanced class weights\n",
    "class_weights_est = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m4.xlarge',\n",
    "    output_path='s3://{}/{}/class_weights/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    hyperparameters={\n",
    "        'feature_dim': 30,\n",
    "        'predictor_type': 'binary_classifier',\n",
    "        'binary_classifier_model_selection_criteria': 'precision_at_target_recall', \n",
    "        'target_recall': 0.9,\n",
    "        'positive_example_weight_mult': 'balanced',\n",
    "        'epochs': 40\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: train and deploy the model\n",
    "class_weights_est.fit({'train': s3_train_path})\n",
    "\n",
    "class_weights_predictor = class_weights_est.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.m4.xlarge'\n",
    ")\n",
    "class_weights_predictor.content_type = 'text/csv'\n",
    "class_weights_predictor.serializer = csv_serializer\n",
    "class_weights_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluate the deployed estimator\n",
    "evaluate(class_weights_predictor, test_features, test_labels, 'ClassWeights', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note on target vs. observed recall\n",
    "\n",
    "It's worth taking some time to look more closely at these results.  If we asked linear learner for a model calibrated to a target recall of 0.9, then why didn't we get exactly 90% recall on the test set?  The reason is the difference between training, validation, and testing.  Linear learner calibrates thresholds for binary classification on the validation data set when one is provided, or else on the training set.  Since we did not provide a validation data set, the threshold were calculated on the training data.  Since the training, validation, and test data sets don't match exactly, the target recall we request is only an approximation.  In this case, the threshold that produced 90% recall on the training data happened to produce only 85-90% recall on the test data (due to some randomness in training, the results will vary from one run to the next).  The variation of recall in the test set versus the training set is dependent on the number of positive points. In this example, although we have over 280,000 examples in the entire dataset, we only have 337 positive examples, hence the large difference.  The accuracy of this approximation can be improved by providing a large validation data set to get a more accurate threshold, and then evaluating on a large test set to get a more accurate benchmark of the model and its threshold.  For even more fine-grained control, we can set the number of calibration samples to a higher number.  It's default value is already quite high at 10 million samples:\n",
    "\n",
    "    num_calibration_samples=10000000,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note on the SageMaker SDK\n",
    "Note that there is also this handy LinearLearner class in the SageMaker SDK: https://sagemaker.readthedocs.io/en/stable/algorithms/linear_learner.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Up\n",
    "\n",
    "Finally we'll clean up by deleting the prediction endpoints we set up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for predictor in [defaults_predictor, autothresh_predictor, class_weights_predictor]:\n",
    "    delete_endpoint(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've just shown how to use the linear learner new early stopping feature, new loss functions, and new class weights feature to improve credit card fraud prediction.  Class weights can help you optimize recall or precision for all types of fraud detection, as well as other classification problems with rare events, like ad click prediction or mechanical failure prediction.  Try using class weights in your binary classification problem, or try one of the new loss functions for your regression problems: use quantile prediction to put confidence intervals around your predictions by learning 5% and 95% quantiles.  For more information about new loss functions and class weights, see the linear learner [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### References\n",
    "Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015.  See link to full license text on [Kaggle](https://www.kaggle.com/mlg-ulb/creditcardfraud)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
